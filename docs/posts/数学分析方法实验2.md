---
title: 数学分析方法实验2
date: 2023-04-28 13:52:16
tags:
- 实验报告
- 大数据分析
Categories:
- 大数据分析方法
- 实验报告
---

## 一、实验目的

通过正则化方法，在定义误差函数时增加惩罚项，来抑制过拟合问题。

## 二、基本原理分析

A、通过实验一的结果可以分析如下：

（1）当 M = 0 和 1 时，多项式的拟合效果很差，即欠拟合现象。 （2）当 M = 3 时，多项式拟合比较好。 （3）当 M = 9 时，多项式函数精确地通过每个观测点，但是曲线呈 现震荡形式并对噪声敏感，出现过拟合现象。

![](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281354662.png)

B、解决办法

通过正则化方法，在定义误差函数时增加惩罚项，使多项式系数被有效控制，不会过大。

![正则化](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281356868.png)

误差函数变成如下形式：

![误差函数](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281358901.png)

## 三、实验过程

**第一步：生成数据**

生成𝑁个数据𝑋 = ( 𝑥 1 , . . . . . , 𝑥 𝑁 ) 𝑇 , 𝑋均匀分布于区间[0,1]:

`𝑋 = 𝑛𝑝 . 𝑙𝑖𝑛𝑠𝑝𝑎𝑐𝑒 ( 0 , 1 , 𝑁 ) `，

𝑋对应的$𝑇=( 𝑡_1 ,. . . . . , 𝑡_𝑁 )$ ，其中，$𝑡𝑖 = sin ( 2𝜋𝑥 ) + 𝑛𝑝. 𝑟𝑎𝑛𝑑𝑜𝑚. 𝑛𝑜𝑟𝑚𝑎𝑙( 𝑠𝑐𝑎𝑙𝑒 = 0.15 , 𝑠𝑖𝑧𝑒 = 𝑁 ) , 𝑖 = 1 , … , 𝑁.(𝑥𝑖, 𝑡𝑖 )$ ，其中 $𝑖=1 , … , 𝑁$，即为生成的样本集。假设样本集包含 10 个点，则𝑁 =10。

**第二步：拟合生成数据**

使用多项式函数来拟合生成的数据。多项式定义如下：
$$
𝑦( 𝑥 , 𝒘 ) 𝑤_0 + 𝑤_1 𝑥 + 𝑤_2 𝑥_2 + . . . +𝑤_𝑀 𝑥^𝑀 =  ∑_{𝑗 = 0}^𝑀 𝑤_𝑗 𝑥_𝑗 .
$$
其中，𝑀 是多项式的阶数,$𝑥_𝑗$ 表示 𝑥 的 𝑗 次幂。多项式系数 $𝑤_0 , … , 𝑤$ 𝑀 记作向量 𝒘 。 多项式系数的求解可以通过最小化误差函数来实现，误差函数衡量了每个数 据点 𝑥𝑖 的预测值 𝑦( 𝑥𝑖 , 𝒘 ) 与目标值 $𝑡_𝑖$ 之间的差异。最常用的误差函数为均方误差函数，定义如下：
$$
𝐸 ( 𝒘 ) = \frac{1}{2}∑_{𝑖 = 1}^𝑁 {𝑦( 𝑥_𝑖 , 𝒘 ) − 𝑡_𝑖 }.
$$
因为误差函数是多项式系数 𝒘 的二次函数，所以存在唯一最小值，且在导数为零处取得。

**第三步：画出不同λ时候的拟合情况**

我们进行当多项式阶数 M = 9 时，有 N = 10 个采样点的情况下， λ较小和较大时（如 $lnλ = − 18$ 和 $l n λ = 0$ ） 时对过拟合现象的实验。

**第四步：处理过拟合的过程**

在训练数据有限的情况下，过高的模型复杂度可能导致模型对训练数据过度拟合，无法很好地泛化到新的数据上，出现过拟合现象。为了避免过拟合现象的发生，我们可以引入正则化项来限制模型的复杂度。

在多项式函数拟合中，我们可以使用L2正则化项，它可以惩罚模型参数的平方和，使得模型参数趋向于较小的值，从而降低模型的复杂度。L2正则化项的形式为：
$$
λ/2 * ||w||^2
$$
其中，λ是正则化参数，w是模型参数。我们可以在多项式函数拟合的损失函数中加入L2正则化项，得到新的损失函数：
$$
J(w) = 1/2 * ||Xw - t||^2 + λ/2 * ||w||^2
$$
其中，X是训练数据的特征矩阵，t是训练数据的标签向量。我们可以使用梯度下降等优化算法，求解上述损失函数的最优解。在求解过程中，由于加入了正则化项，所以模型参数的值会趋向于较小的值，从而限制了模型的复杂度。通过调节正则化参数λ的值，我们可以控制正则化的强度。

**源码**

```python
import numpy as np
import matplotlib.pyplot as plt

# 生成数据
N = 10
x = np.linspace(0, 1, N)
t = np.sin(2 * np.pi * x) + np.random.normal(scale=0.3, size=N)

# 多项式函数拟合
def polynomial_fit(x, t, M):
    X = np.array([x ** i for i in range(M+1)]).T
    w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(t)
    return w

# 画图函数
def plot_fit(x, t, w, M):
    xx = np.linspace(0, 1, 100)
    yy = np.array([w.dot(np.array([xi**i for i in range(M+1)])) for xi in xx])
    plt.plot(x, t, 'o')
    plt.plot(xx, np.sin(2 * np.pi * xx), 'g--')
    plt.plot(xx, yy, 'r-')
    plt.title(f"M={M}")
    plt.show()


# 实验
Ms = [1, 3, 9]
for M in Ms:
    w = polynomial_fit(x, t, M)
    plot_fit(x, t, w, M)

```

## 四、结果分析

我们首先使用 numpy 生成了一组包含噪声的数据。然后，定义了一个多项式函数拟合的函数 polynomial_fit，其中没有包含正则化项。接着，我们定义了一个画图函数 plot_fit，用于画出拟合结果和原始数据。最后，我们在 $M = 1、3、9$ 的情况下，对拟合结果进行了实验。

根据实验的结果，我们可以发现在 $M = 1$ 的情况下，模型拟合程度不足，不能很好地拟合原始数据。而在 $M = 9$ 的情况下，模型过拟合现象明显，对噪声数据过度拟合，不能很好地泛化到新的数据。只有在 $M = 3$ 的情况下，模型能够较好地拟合原始数据，并且不出现过拟合现象。

针对过拟合现象，我们采取以下措施：

1. 增加训练数据：增加训练数据可以提高模型的泛化能力，减少过拟合现象的发生。
2. 减少特征数：减少特征数可以降低模型的复杂度，减少过拟合现象的发生。
3. 引入正则化项：引入正则化项可以限制模型的复杂度，减少过拟合现象的发生。例如，可以在 polynomial_fit 函数中添加一个 L2 正则化项。

通过实验，我们可以发现在多项式拟合中容易出现过拟合现象，需要采取相应的措施来处理。只有在选择合适的模型复杂度和采取合适的过拟合处理措施之后，才能够得到较好的拟合结果。

**下面展示在不同阶数处理的效果**

为进行正则化处理之前：

**在阶数为一的情况下（欠拟合）：**

![Figure_1](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281426138.png)

**在阶数为三的情况下：（最优拟合的情况）**

![Figure_2](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281426382.png)

**在阶数为9的情况下（过拟合）**

![Figure_3](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281427032.png)

进行正则化处理之后：

**在阶数为一的情况下（欠拟合）**

![Figure_4](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281445493.png)

**在阶数为三的情况下：（最优拟合的情况）**

![Figure_5](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281446712.png)

**在阶数为9的情况下（过拟合）**

![Figure_6](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281446563.png)

在多项式函数拟合中，使用了L2正则化项，它可以惩罚模型参数的平方和，使得模型参数趋向于较小的值，从而降低模型的复杂度。L2正则化项的形式为：
$$
λ/2 * ||w||^2
$$
其中，λ是正则化参数，w是模型参数。在多项式函数拟合的损失函数中加入L2正则化项，得到新的损失函数：
$$
J(w) = 1/2 * ||Xw - t||^2 + λ/2 * ||w||^2
$$
其中，X是训练数据的特征矩阵，t是训练数据的标签向量。我们使用梯度下降的优化算法，求解上述损失函数的最优解。在求解过程中，由于加入了正则化项，所以模型参数的值会趋向于较小的值，从而限制了模型的复杂度。通过调节正则化参数λ的值，我们可以控制正则化的强度。
