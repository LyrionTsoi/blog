---
title: 人工智能课程设计报告
date: 2023-04-11 14:39:55
tags:
- 课程设计
- 人脸识别
- 报告
---

## 一、简介

Dlib是一个基于C++的跨平台开源机器学习库，用于开发可重用和高性能的软件。Dlib库涉及许多领域，包括图像处理和计算机视觉。其中，Dlib的人脸识别算法得到了广泛关注和应用，可以用于实现快速、准确的人脸识别和跟踪等应用，本报告将以一个基于Dlib库的人脸识别项目为例，介绍如何使用Dlib库实现人脸识别算法。

## 二、实验过程

### 1. 准备工作

在开始这个项目之前，需要先安装好Dlib库，并了解它的基本用法。Dlib库支持Windows、Linux和MacOS等操作系统，它使用C++编写，但也提供了Python的接口。在本项目中，我们将使用Dlib Python接口来实现人脸识别算法。

### 2. 数据集准备

人脸识别算法需要一个用于训练和测试的数据集。在本项目中，我们利用了全班27位同学的照片。大约每个人的正脸加上微侧脸图片15张的，训练的样本。

### 3. 数据预处理

对于每个训练和测试图像，我们需要提取出其中的人脸，并将其转换为一组向量。为了完成这个操作，我们使用了OpenCV库中的人脸检测器，使用Dlib库中的面部关键点检测器来定位人脸，并将其转换为具有固定长度的向量。此外，我们还需要对数据进行标准化，以便在训练和测试集上实现更好的性能。具体可以实现的方法有以下几点：

1. 图像归一化：人脸图像的大小、光照、角度等因素可能会对识别结果产生影响。为了解决这些问题，可以将图像进行归一化操作。具体来说，可以将人脸图像缩放到固定的大小，例如128x128，然后通过插值算法将缩放后的图像还原成原始大小。这样可以保证输入图像的大小一致，并且减小了噪声的影响。
2. 直方图均衡：直方图均衡可以增加图像的对比度，提高图像的质量，从而提高识别准确率。具体来说，可以将图像的颜色空间转换到YUV色彩空间，然后对Y通道进行直方图均衡化。这样可以增加图像的对比度，使得人脸特征更加明显。
3. 人脸对齐：人脸对齐可以解决人脸图像中的旋转和倾斜问题，提高模型的鲁棒性。具体来说，可以通过检测人脸关键点，然后将人脸旋转到一个固定的角度，例如水平方向。这样可以使得人脸图像更加一致，减小了特征的差异性。
4. 数据增强：数据增强可以增加训练数据的数量，提高模型的泛化能力。具体来说，可以通过对图像进行平移、旋转、缩放等操作，生成新的训练数据。这样可以使得模型更加鲁棒，减小了过拟合的风险。
5. 去除噪声：人脸图像中可能存在噪声，例如光照不均、阴影等。这些噪声会影响模型的准确率。为了解决这些问题，可以使用滤波器，例如高斯滤波器、中值滤波器等，去除图像中的噪声。

### 4. 模型的参数调试 

dlib中的人脸识别模块默认使用的是已经经过训练的神经网络模型，因此一般情况下不需要进行调参。但是，如果使用自己的数据集进行训练，或者想对默认的参数进行微调，可以考虑以下几点：

1. 数据集的选择：在进行人脸识别的训练时，需要有足够量的人脸图像数据集，以保证训练出来的模型具有较高的准确率。因此，在选择数据集时需要注意，数据集应该具有足够的样本数量和多样性，以尽可能地覆盖各种不同的人脸特征。
2. 网络结构的选择：在进行人脸识别的训练时，需要根据数据集的特点，选择合适的卷积神经网络结构。dlib中的人脸识别模块使用的是ResNet-34网络结构，但是这并不一定适用于所有的数据集。因此，在进行训练时，需要根据实际情况进行网络结构的选择。
3. 训练参数的调整：在进行人脸识别的训练时，需要对训练参数进行调整，以达到最佳的训练效果。例如，学习率、批次大小、训练迭代次数等参数都会影响训练效果。可以通过交叉验证等方法来确定最佳的参数组合。
4. 数据预处理：在进行人脸识别的训练时，需要对数据进行预处理，以提高训练效果。例如，对图像进行归一化、旋转、裁剪等操作，可以使得训练更加鲁棒。

### 5. 训练和测试

在准备好数据之后，我们可以使用Dlib的线性判别分析算法（LDA）来进行训练。该算法将用于将每个人的面部图像转换为相应的向量，并生成一个人脸空间，以便我们可以度量测试样本与已知样本之间的差异。在训练完成后，我们还需要对测试数据进行分类，并根据分类结果计算测试精度。

具体训练过程我们可以使用Dlib库中的一下的人脸算法

1. HOG（方向梯度直方图）特征+SVM分类器：Dlib库最早的人脸识别算法就是基于HOG特征和SVM分类器的。该算法将人脸图像分成不同大小的单元格，计算每个单元格的HOG特征，并使用SVM分类器对这些特征进行分类。该算法的优点是速度快，适用于实时的人脸识别，但准确率相对较低。
2. 人脸关键点检测器：Dlib库中的人脸关键点检测器可以检测人脸的68个关键点，包括眼睛、鼻子、嘴巴等。这些关键点可以用于人脸对齐、表情识别、眼部跟踪等应用。
3. 人脸识别模块：Dlib库中的人脸识别模块使用深度学习算法，基于ResNet-34网络结构，可以对人脸进行特征提取和识别。该模块可以识别多个人脸，并返回每个人脸的128维特征向量，可以用于人脸识别、人脸验证等应用。
4. 人脸表情识别模型：Dlib库中的人脸表情识别模型基于卷积神经网络（CNN）算法，可以识别人脸的表情，包括高兴、悲伤、惊讶等。该模型可以用于情感分析、人机交互等应用。
5. 人脸模板匹配算法：Dlib库中的人脸模板匹配算法基于模板匹配的思想，可以用于快速检测人脸。该算法通过将人脸分成不同的部分，并计算每个部分的特征向量，然后使用模板匹配算法进行匹配，以检测人脸。

### 6. 模型测试

在完成训练和测试后，我们将使用一些性能指标来评估人脸识别算法的性能。我们可能需要一些评价函数去对我们模型做一定调整。以下是一些可能有用的评价函数：

1. 准确率：准确率是一个常用的评价指标，可以用来衡量模型对测试集的识别准确率。准确率的计算公式为：正确识别的人脸数/总人脸数。可以使用sklearn库中的accuracy_score函数进行计算。

   ```python
   from sklearn.metrics import accuracy_score
   
   y_true = [0, 1, 0, 1]
   y_pred = [0, 1, 1, 1]
   accuracy = accuracy_score(y_true, y_pred)
   print("Accuracy: %.2f%%" % (accuracy * 100))
   ```

2. 召回率：召回率是另一个常用的评价指标，可以用来衡量模型对测试集中所有人脸的识别能力。召回率的计算公式为：正确识别的人脸数/总测试集中的人脸数。可以使用sklearn库中的recall_score函数进行计算。

   ```python
   from sklearn.metrics import recall_score
   
   y_true = [0, 1, 0, 1]
   y_pred = [0, 1, 1, 1]
   recall = recall_score(y_true, y_pred)
   print("Recall: %.2f%%" % (recall * 100))
   ```

3. F1分数：F1分数是准确率和召回率的调和平均数，可以同时考虑模型的准确率和召回率。F1分数的计算公式为：2 * (准确率 * 召回率) / (准确率 + 召回率)。可以使用sklearn库中的f1_score函数进行计算。

   ```python
   from sklearn.metrics import f1_score
   
   y_true = [0, 1, 0, 1]
   y_pred = [0, 1, 1, 1]
   f1 = f1_score(y_true, y_pred)
   print("F1-score: %.2f%%" % (f1 * 100))
   ```

4. ROC曲线：ROC曲线是一种常用的评价指标，可以用来衡量模型的性能。ROC曲线是以假阳性率（false positive rate）为横坐标，真阳性率（true positive rate）为纵坐标画出的曲线，可以用来评估模型在不同阈值下的性能表现。可以使用sklearn库中的roc_curve函数绘制ROC曲线。

5. AUC指标：AUC指标是ROC曲线下的面积，可以用来衡量模型的性能。AUC的取值范围为0到1，值越接近1表示模型的性能越好。可以使用sklearn库中的roc_auc_score函数计算AUC指标。

   ```python
   from sklearn.metrics import roc_auc_score
   
   y_true = [0, 1, 0, 1]
   y_scores = [0.1, 0.4, 0.35, 0.8] # 预测为正类的概率或得分
   auc = roc_auc_score(y_true, y_scores)
   print("AUC: %.2f%%" % (auc * 100))
   ```

但是这个模型由于要通过实时识别人脸数据来进行大量的测试，所以在使用不同的模型测试的时候比较复杂。操作比较繁琐，这里不再赘述。

### 7. 实验大体流程图

![](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304191712131.png)

## 三、原理介绍

人脸识别技术依赖于人脸图像的数据处理，其核心原理是在一张人脸图像中提取出具有代表性的特征，再将这些特征与已存储在数据库中的模板进行比对，以确定身份。在不同的人脸识别算法中，通常有两种方法来提取人脸特征：基于颜色空间的特征提取和基于纹理算法的特征提取。当语义信息和对光照和尺度变化的适应变得更加稳定时，人脸识别算法将变得更加准确和灵敏。

在完成了整个实验流程后，我们来介绍一下使用Dlib库实现人脸识别算法的基本原理。Dlib库中的人脸识别算法基于线性判别分析（LDA）和人脸特征向量（Face Feature Vector）实现。其中，LDA是一种常用的线性分类器，它可以将具有更高可区分性的特征映射到一个更高维的空间中，在这个空间中，不同类别之间的差异更加明显。而一个人的人脸特征向量是由其面部图像中的某些局部特征的几何关系构成的，这些特征通常被称为landmarks或keypoints，它们的位置和形态与人脸的形态有关，一般包括眼睛、鼻子、嘴巴等特征，每个特征都被表示为一个向量。Dlib库中的人脸识别算法通过提取和比较人脸特征向量来实现人脸识别。

在dlib中的人脸识别模块中，首先使用深度卷积神经网络来将输入的图像转换成128维的向量，然后使用欧氏距离来计算两个向量之间的相似度，从而进行人脸识别。

具体来说，dlib中的人脸识别模块使用了ResNet-34网络结构，该网络结构是由残差网络（Residual Networks，ResNet）所扩展而来。ResNet通过引入残差块（Residual Block）来解决深度神经网络的梯度消失问题，从而使得网络可以更深，精度更高。

在dlib中的人脸识别模块中，ResNet-34网络结构的输入是一张人脸图像，经过多个卷积层和残差块之后，输出一个128维的向量。这个向量就是该人脸的特征向量，可以用于后续的人脸匹配和识别。

对于两个人脸的特征向量，dlib使用欧氏距离来计算它们之间的相似度。欧氏距离公式如下：
$$
d(x,y)=\sqrt{\sum_{i=1}^n(x_i-y_i)^2}
$$
其中，$x$和$y$是两个向量，$n$是向量的维度。

因此，在dlib中的人脸识别模块中，当两个人脸的特征向量之间的欧氏距离越小，说明它们之间的相似度越高，认为它们属于同一个人的概率也就越大。

总之，dlib中的人脸识别模块使用了深度卷积神经网络和欧氏距离算法来实现人脸识别，其中ResNet-34网络结构用于提取人脸的特征向量，欧氏距离用于计算两个特征向量之间的相似度。

## 四、 代码分析与介绍

`Recognize.py`的主要功能是通过计算机摄像头捕捉图像，然后使用Dlib库进行人脸检测和识别。以下是代码分析：

1. 导入所需库：

```python
import dlib
import numpy as np
import cv2
```

2. 加载预训练的Dlib模型：

```python
# 人脸检测器
detector = dlib.get_frontal_face_detector()
# 人脸关键点检测器
predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')
# 人脸识别模型
face_rec = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")
```

3. 定义一个函数，将矩形框转换为正方形框：

```python
def rect_to_square(rect):
    pass
```

4. 定义一个函数，计算欧氏距离：

```python
def return_euclidean_distance(feature_1, feature_2):
    pass
```

5. 设定摄像头参数并打开摄像头：

```python
# 摄像头参数
cap = cv2.VideoCapture(0)
cap.set(3, 480)
```

6. 主循环：

- 读取摄像头帧
- 将帧转换为灰度图像
- 使用Dlib人脸检测器检测人脸
- 对检测到的人脸进行遍历
  - 获取人脸关键点
  - 提取人脸特征
  - 计算与已知人脸特征的欧氏距离
  - 根据距离判断是否为同一个人
  - 在图像上画出人脸框和识别结果

`get_face_from_camera`从摄像头当中提取出人脸特征

1. 导入所需库：

   ````python
   import dlib
   import numpy as np
   import cv2
   import os
   import shutil
   import sys
   ```

   - `dlib`：一个包含机器学习算法的 C++ 库，有 Python 绑定。
   - `numpy`：一个用于处理数组数据的库。
   - `cv2`：OpenCV 库，用于处理计算机视觉任务。
   - `os` 和 `shutil`：用于处理文件和目录操作。
   - `sys`：用于访问 Python 运行时的系统参数。

2. 初始化 Dlib 面部检测器、预测器和识别模型：

   ````python
   detector = dlib.get_frontal_face_detector()
   predictor = dlib.shape_predictor("shape_predictor_5_face_landmarks.dat")
   face_rec = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")
   ```

   - `dlib.get_frontal_face_detector()`：返回一个用于检测正面人脸的对象。
   - `dlib.shape_predictor()`：从预先训练的模型文件中加载一个用于预测面部特征点的对象。
   - `dlib.face_recognition_model_v1()`：从预先训练的模型文件中加载一个用于识别面部的对象。

3. 定义一个函数 `return_euclidean_distance()` 计算两个向量之间的欧几里得距离。

4. 获取摄像头的视频流，并对每一帧进行处理：

   ````python
   while cap.isOpened():
       flag, img_rd = cap.read()
       # ...
       dets = detector(img_gray, 0)
       # ...
   ```

   - `cap.isOpened()`：检查摄像头是否已打开。
   - `cap.read()`：从摄像头捕获一帧图像，返回一个标志和图像。
   - `detector(img_gray, 0)`：在灰度图像上执行面部检测。

5. 对于检测到的每个人脸，执行以下操作：

   ````python
   for k, d in enumerate(dets):
       # ...
       shape = predictor(img_rd, d)
       # ...
       face_descriptor = face_rec.compute_face_descriptor(img_rd, shape)
       # ...
   ```

   - `predictor(img_rd, d)`：在检测到的人脸区域上执行面部特征点预测。
   - `face_rec.compute_face_descriptor(img_rd, shape)`：计算输入图像中的人脸的特征描述符。

6. 将人脸描述符与已知人脸列表进行比较，计算欧几里得距离：

   ````python
   e_distance = return_euclidean_distance(face_descriptor, known_face_encodings[i])
   ```

7. 如果欧几里得距离小于某个阈值，将人脸标记为已知人脸，否则标记为未知人脸。

8. 在显示的视频帧上绘制人脸边界框和名称标签。

9. 检查用户是否按下了 "q" 键，如果是，则关闭摄像头并退出程序。

使用 Dlib 库从摄像头捕获实时视频，检测图像中的人脸，提取面部特征，然后将这些特征与已知的面部特征列表进行比较。根据比较结果，程序将人脸标记为已知或未知，并在实时视频的每一帧上显示这些信息。

`features_to_csv.py` 特征转换

这个代码用于使用Dlib库实现人脸识别，并将提取到的人脸特征向量存储到CSV文件中。下面是逐行的解释：

```python
import dlib
import numpy as np
import cv2
import pandas as pd
import os
```

以上代码导入了所需的库。主要使用了`dlib`进行人脸识别，`numpy`和`pandas`处理数据，`cv2`（OpenCV）进行摄像头输入以及图像处理，`os`处理文件系统操作。

```python
# Dlib 预测器
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('shape_predictor_5_face_landmarks.dat')
face_rec = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")
```

这些行实例化了Dlib的人脸检测器、形状预测器和人脸识别模型。形状预测器和人脸识别模型需要预先训练好的数据文件（`.dat`）。

```python
# 读取存放所有人脸特征的 csv
path_features_known_csv = "features_all.csv"
csv_rd = pd.read_csv(path_features_known_csv, header=None)
```

这部分代码读取包含已知人脸特征向量的CSV文件。`header=None`表示CSV文件没有列名。

```python
# 存储的特征人脸个数
# print(csv_rd.shape[0])

# 用来存放所有录入人脸特征的数组
features_known_arr = []

# known faces
for i in range(csv_rd.shape[0]):
    features_someone_arr = []
    for j in range(0, 128):
        features_someone_arr.append(csv_rd.iat[i, j])
    features_known_arr.append(features_someone_arr)
print("Faces in Database：", len(features_known_arr))
```

这部分代码将CSV文件中的已知人脸特征向量存储到名为`features_known_arr`的列表中。这是一个嵌套列表，其中每个人脸特征向量都是一个包含128个特征值的列表。

```python
# 创建 cv2 摄像头对象
cap = cv2.VideoCapture(0)

# cap.set(propId, value)
# 设置视频参数，propId 设置的视频参数，value 设置的参数值
cap.set(3, 480)
```

这部分代码使用OpenCV创建摄像头对象，并设置摄像头的分辨率。

```python
# 截图 screenshoot 的计数器
ss_cnt = 0
```

初始化用于计算屏幕截图数量的计数器。

```python
while cap.isOpened():
```

这行代码开始主循环，当摄像头打开时持续执行。

下面是主循环中的代码，简要说明了其功能：

1. 从摄像头捕获帧。
2. 将捕获的帧转换为灰度图像。
3. 使用Dlib的人脸检测器在灰度图像上检测人脸。
4. 对于检测到的每个人脸，使用形状预测器在原始图像上找到面部特征点，并对该区域进行对齐。
5. 对齐后的面部图像传递给人脸识别模型，以提取128维特征向量。
6. 将当前检测到的特征向量与已知特征向量进行比较，计算欧氏距离。
7. 使用阈值（默认为0.4）确定当前面部是否与已知面部匹配。
8. 绘制人脸边界框，并在已知面部的情况下来在屏幕上显示名称。
9. 当按下"s"键时，将当前帧的人脸特征向量保存到CSV文件中，并将屏幕截图计数器加1。
10. 当按下"q"键时，退出主循环。
11. 显示摄像头捕获的帧。

```python
cap.release()
cv2.destroyAllWindows()
```

在主循环结束后，关闭摄像头并销毁所有窗口。

总之，这个代码使用Dlib库进行摄像头输入的实时人脸识别，并将识别到的人脸特征向量保存到CSV文件中。用户可以通过按"s"键保存当前帧的人脸特征向量，以便在未来的识别任务中使用。

## 五、效果展示

单人识别效果：

![](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304221515375.png)

多人识别效果：

- 

  ![两人识别](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281651007.png)

- 三个人识别

  ![三人识别](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281650633.png)

人物超出框内识别效果（异常识别）：![异常](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281653840.png)



非数据库人物识别效果：

![unknow](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304240958907.png)

非数据库人物与数据库人物识别效果

![unknow+know](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202304281654868.png)

以上图片均经过上镜同学同意

## 六、未来发展趋势

人脸识别技术的未来发展趋势主要体现在以下几个方面：

1. 多模态融合：将人脸识别和声纹识别、生物电信号或者其他生物信息结合起来，提高整个生物识别的安全性和可靠性。

2. 可解释性：让深度学习模型的结果更易于被人理解，在模型识别错误时，找到错误原因以降低错误率。

3. 联邦学习：可以让数据不离开原来的位置，并且想要获得模型，则模型从移动端完成模型更新。它将消除所有数据需集中到中央服务器上的限制，并且更好地保护了隐私。

总之，人工智能技术的发展为人脸识别的提高提供了极大的可能性，而人脸识别的发展也将会带宽新的技术革命和行业变革。

## 七、 实验源码

`Recognize 识别代码`

```python
# 识别代码
import dlib
import numpy as np
import cv2
import pandas as pd
import os
import time
import logging
from PIL import Image, ImageDraw, ImageFont

# Dlib 正向人脸检测器 
detector = dlib.get_frontal_face_detector()

# Dlib 人脸 landmark 特征点检测器 
predictor = dlib.shape_predictor('data/data_dlib/shape_predictor_68_face_landmarks.dat')

# Dlib Resnet 人脸识别模型，提取 128D 的特征矢量 
face_reco_model = dlib.face_recognition_model_v1("data/data_dlib/dlib_face_recognition_resnet_model_v1.dat")


class Face_Recognizer:
    def __init__(self):
        self.face_feature_known_list = []                # 用来存放所有录入人脸特征的数组 
        self.face_name_known_list = []                   # 存储录入人脸名字 

        self.current_frame_face_cnt = 0                     # 存储当前摄像头中捕获到的人脸数 / Counter for faces in current frame
        self.current_frame_face_feature_list = []           # 存储当前摄像头中捕获到的人脸特征 / Features of faces in current frame
        self.current_frame_face_name_list = []              # 存储当前摄像头中捕获到的所有人脸的名字 / Names of faces in current frame
        self.current_frame_face_name_position_list = []     # 存储当前摄像头中捕获到的所有人脸的名字坐标 / Positions of faces in current frame

        # Update FPS
        self.fps = 0                    # FPS of current frame
        self.fps_show = 0               # FPS per second
        self.frame_start_time = 0
        self.frame_cnt = 0
        self.start_time = time.time()

        self.font = cv2.FONT_ITALIC
        self.font_chinese = ImageFont.truetype("simsun.ttc", 30)

    # 从 "features_all.csv" 读取录入人脸特征 / Read known faces from "features_all.csv"
    def get_face_database(self):
        if os.path.exists("data/features_all.csv"):
            path_features_known_csv = "data/features_all.csv"
            csv_rd = pd.read_csv(path_features_known_csv, header=None)
            for i in range(csv_rd.shape[0]):
                features_someone_arr = []
                self.face_name_known_list.append(csv_rd.iloc[i][0])
                for j in range(1, 129):
                    if csv_rd.iloc[i][j] == '':
                        features_someone_arr.append('0')
                    else:
                        features_someone_arr.append(csv_rd.iloc[i][j])
                self.face_feature_known_list.append(features_someone_arr)
            logging.info("Faces in Database：%d", len(self.face_feature_known_list))
            return 1
        else:
            logging.warning("'features_all.csv' not found!")
            logging.warning("Please run 'get_faces_from_camera.py' "
                            "and 'features_extraction_to_csv.py' before 'face_reco_from_camera.py'")
            return 0

    # 计算两个128D向量间的欧式距离 / Compute the e-distance between two 128D features
    @staticmethod
    def return_euclidean_distance(feature_1, feature_2):
        feature_1 = np.array(feature_1)
        feature_2 = np.array(feature_2)
        dist = np.sqrt(np.sum(np.square(feature_1 - feature_2)))
        return dist

    # 更新 FPS / Update FPS of Video stream
    def update_fps(self):
        now = time.time()
        # 每秒刷新 fps / Refresh fps per second
        if str(self.start_time).split(".")[0] != str(now).split(".")[0]:
            self.fps_show = self.fps
        self.start_time = now
        self.frame_time = now - self.frame_start_time
        self.fps = 1.0 / self.frame_time
        self.frame_start_time = now

    # 生成的 cv2 window 上面添加说明文字 / PutText on cv2 window
    def draw_note(self, img_rd):
        # cv2.putText(img_rd, "Face Recognizer", (20, 40), self.font, 1, (255, 255, 255), 1, cv2.LINE_AA)
        # cv2.putText(img_rd, "Frame:  " + str(self.frame_cnt), (20, 100), self.font, 0.8, (0, 255, 0), 1,
        #             cv2.LINE_AA)
        # cv2.putText(img_rd, "FPS:    " + str(self.fps_show.__round__(2)), (20, 130), self.font, 0.8, (0, 255, 0), 1,
        #             cv2.LINE_AA)
        # cv2.putText(img_rd, "Faces:  " + str(self.current_frame_face_cnt), (20, 160), self.font, 0.8, (0, 255, 0), 1,
        #             cv2.LINE_AA)
        cv2.putText(img_rd, " ", (20, 450), self.font, 0.8, (255, 255, 255), 1, cv2.LINE_AA)

    def draw_name(self, img_rd):
        # 在人脸框下面写人脸名字 / Write names under rectangle
        img = Image.fromarray(cv2.cvtColor(img_rd, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img)
        for i in range(self.current_frame_face_cnt):
            # cv2.putText(img_rd, self.current_frame_face_name_list[i], self.current_frame_face_name_position_list[i], self.font, 0.8, (0, 255, 255), 1, cv2.LINE_AA)
            draw.text(xy=self.current_frame_face_name_position_list[i], text=self.current_frame_face_name_list[i], font=self.font_chinese,
                  fill=(255, 255, 0))
            img_rd = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        return img_rd

    # 修改显示人名 
    def show_chinese_name(self):
        # Default known name: person_1, person_2, person_3
        if self.current_frame_face_cnt >= 1:
            # 修改录入的人脸姓名 
            self.face_name_known_list[0] = '张三'.encode('utf-8').decode()
            # self.face_name_known_list[1] = '张四'.encode('utf-8').decode()

    # 处理获取的视频流，进行人脸识别 
    def process(self, stream):
        # 1. 读取存放所有人脸特征的 csv
        if self.get_face_database():
            while stream.isOpened():
                self.frame_cnt += 1
                logging.debug("Frame %d starts", self.frame_cnt)
                flag, img_rd = stream.read()
                faces = detector(img_rd, 0)
                kk = cv2.waitKey(1)
                # 按下 q 键退出 
                if kk == ord('q'):
                    break
                else:
                    self.draw_note(img_rd)
                    self.current_frame_face_feature_list = []
                    self.current_frame_face_cnt = 0
                    self.current_frame_face_name_position_list = []
                    self.current_frame_face_name_list = []

                    # 2. 检测到人脸 / Face detected in current frame
                    if len(faces) != 0:
                        # 3. 获取当前捕获到的图像的所有人脸的特征 / Compute the face descriptors for faces in current frame
                        for i in range(len(faces)):
                            shape = predictor(img_rd, faces[i])
                            self.current_frame_face_feature_list.append(face_reco_model.compute_face_descriptor(img_rd, shape))
                        # 4. 遍历捕获到的图像中所有的人脸 / Traversal all the faces in the database
                        for k in range(len(faces)):
                            logging.debug("For face %d in camera:", k+1)
                            # 先默认所有人不认识，是 unknown / Set the default names of faces with "unknown"
                            self.current_frame_face_name_list.append("unknown")

                            # 每个捕获人脸的名字坐标 / Positions of faces captured
                            self.current_frame_face_name_position_list.append(tuple(
                                [faces[k].left(), int(faces[k].bottom() + (faces[k].bottom() - faces[k].top()) / 4)]))

                            # 5. 对于某张人脸，遍历所有存储的人脸特征
                            # For every faces detected, compare the faces in the database
                            current_frame_e_distance_list = []
                            for i in range(len(self.face_feature_known_list)):
                                # 如果 person_X 数据不为空
                                if str(self.face_feature_known_list[i][0]) != '0.0':
                                    e_distance_tmp = self.return_euclidean_distance(self.current_frame_face_feature_list[k],
                                                                                    self.face_feature_known_list[i])
                                    logging.debug("  With person %s, the e-distance is %f", str(i + 1), e_distance_tmp)
                                    current_frame_e_distance_list.append(e_distance_tmp)
                                else:
                                    # 空数据 person_X
                                    current_frame_e_distance_list.append(999999999)
                            # 6. 寻找出最小的欧式距离匹配 / Find the one with minimum e-distance
                            similar_person_num = current_frame_e_distance_list.index(min(current_frame_e_distance_list))
                            logging.debug("Minimum e-distance with %s: %f", self.face_name_known_list[similar_person_num], min(current_frame_e_distance_list))

                            if min(current_frame_e_distance_list) < 0.4:
                                self.current_frame_face_name_list[k] = self.face_name_known_list[similar_person_num]
                                logging.debug("Face recognition result: %s", self.face_name_known_list[similar_person_num])
                            else:
                                logging.debug("Face recognition result: Unknown person")
                            logging.debug("\n")

                            # 矩形框 / Draw rectangle
                            for kk, d in enumerate(faces):
                                # 绘制矩形框
                                cv2.rectangle(img_rd, tuple([d.left(), d.top()]), tuple([d.right(), d.bottom()]),
                                              (255, 255, 255), 2)

                        self.current_frame_face_cnt = len(faces)

                        # 7. 在这里更改显示的人名 / Modify name if needed
                        # self.show_chinese_name()

                        # 8. 写名字 / Draw name
                        img_with_name = self.draw_name(img_rd)

                    else:
                        img_with_name = img_rd

                logging.debug("Faces in camera now: %s", self.current_frame_face_name_list)

                cv2.imshow("camera", img_with_name)

                # 9. 更新 FPS / Update stream FPS
                self.update_fps()
                logging.debug("Frame ends\n\n")

    # OpenCV 调用摄像头并进行 process
    def run(self):
        # cap = cv2.VideoCapture("video.mp4")  # Get video stream from video file
        cap = cv2.VideoCapture(0)              # Get video stream from camera
        cap.set(3, 480)                        # 640x480
        self.process(cap)

        cap.release()
        cv2.destroyAllWindows()


def main():
    # logging.basicConfig(level=logging.DEBUG) # Set log level to 'logging.DEBUG' to print debug info of every frame
    logging.basicConfig(level=logging.INFO)
    Face_Recognizer_con = Face_Recognizer()
    Face_Recognizer_con.run()


if __name__ == '__main__':
    main()

```

`特征转换`

```python
# 从人脸图像文件中提取人脸特征存入 "features_all.csv" / Extract features from images and save into "features_all.csv"

import os
import dlib
import csv
import numpy as np
import logging
import cv2

# 要读取人脸图像文件的路径 / Path of cropped faces
path_images_from_camera = "data/data_faces_from_camera/"

# Dlib 正向人脸检测器 / Use frontal face detector of Dlib
detector = dlib.get_frontal_face_detector()

# Dlib 人脸 landmark 特征点检测器 / Get face landmarks
predictor = dlib.shape_predictor('data/data_dlib/shape_predictor_68_face_landmarks.dat')

# Dlib Resnet 人脸识别模型，提取 128D 的特征矢量 / Use Dlib resnet50 model to get 128D face descriptor
face_reco_model = dlib.face_recognition_model_v1("data/data_dlib/dlib_face_recognition_resnet_model_v1.dat")


# 返回单张图像的 128D 特征 / Return 128D features for single image
# Input:    path_img           <class 'str'>
# Output:   face_descriptor    <class 'dlib.vector'>
def return_128d_features(path_img):
    img_rd = cv2.imread(path_img)
    faces = detector(img_rd, 1)

    logging.info("%-40s %-20s", "检测到人脸的图像 / Image with faces detected:", path_img)

    # 因为有可能截下来的人脸再去检测，检测不出来人脸了, 所以要确保是 检测到人脸的人脸图像拿去算特征
    # For photos of faces saved, we need to make sure that we can detect faces from the cropped images
    if len(faces) != 0:
        shape = predictor(img_rd, faces[0])
        face_descriptor = face_reco_model.compute_face_descriptor(img_rd, shape)
    else:
        face_descriptor = 0
        logging.warning("no face")
    return face_descriptor


# 返回 personX 的 128D 特征均值 / Return the mean value of 128D face descriptor for person X
# Input:    path_face_personX        <class 'str'>
# Output:   features_mean_personX    <class 'numpy.ndarray'>
def return_features_mean_personX(path_face_personX):
    features_list_personX = []
    photos_list = os.listdir(path_face_personX)
    if photos_list:
        for i in range(len(photos_list)):
            # 调用 return_128d_features() 得到 128D 特征 / Get 128D features for single image of personX
            logging.info("%-40s %-20s", "正在读的人脸图像 / Reading image:", path_face_personX + "/" + photos_list[i])
            features_128d = return_128d_features(path_face_personX + "/" + photos_list[i])
            # 遇到没有检测出人脸的图片跳过 / Jump if no face detected from image
            if features_128d == 0:
                i += 1
            else:
                features_list_personX.append(features_128d)
    else:
        logging.warning("文件夹内图像文件为空 / Warning: No images in%s/", path_face_personX)

    # 计算 128D 特征的均值 / Compute the mean
    # personX 的 N 张图像 x 128D -> 1 x 128D
    if features_list_personX:
        features_mean_personX = np.array(features_list_personX, dtype=object).mean(axis=0)
    else:
        features_mean_personX = np.zeros(128, dtype=object, order='C')
    return features_mean_personX


def main():
    logging.basicConfig(level=logging.INFO)
    # 获取已录入的最后一个人脸序号 / Get the order of latest person
    person_list = os.listdir("data/data_faces_from_camera/")
    person_list.sort()

    with open("data/features_all.csv", "w", newline="") as csvfile:
        writer = csv.writer(csvfile)
        for person in person_list:
            # Get the mean/average features of face/personX, it will be a list with a length of 128D
            logging.info("%sperson_%s", path_images_from_camera, person)
            features_mean_personX = return_features_mean_personX(path_images_from_camera + person)

            if len(person.split('_', 2)) == 2:
                # "person_x"
                person_name = person
            else:
                # "person_x_tom"
                person_name = person.split('_', 2)[-1]
            features_mean_personX = np.insert(features_mean_personX, 0, person_name, axis=0)
            # features_mean_personX will be 129D, person name + 128 features
            writer.writerow(features_mean_personX)
            logging.info('\n')
        logging.info("所有录入人脸数据存入 / Save all the features of faces registered into: data/features_all.csv")


if __name__ == '__main__':
    main()
```

