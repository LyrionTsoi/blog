---
title: 大数据课程设计小组报告
date: 2023-06-05 19:11:08
tags:
---

# 大数据课程设计

## 实验目的

- 使用决策树模型对手机价格进行分类预测，并与其他模型进行比较，分析决策树模型的优势和局限性。

## 实验数据

- 来自Kaggle的手机价格分类数据集，包含2000个样本，21个特征和4个类别。数据集的描述如下：

|   特征名称    |           特征含义           | 特征类型 |                可能取值                |
| :-----------: | :--------------------------: | :------: | :------------------------------------: |
| battery_power |           电池容量           |  数值型  |                任意整数                |
|     blue      |        是否有蓝牙功能        |  类别型  |                  0或1                  |
|  clock_speed  |          处理器速度          |  数值型  |                任意实数                |
|   dual_sim    |       是否支持双卡双待       |  类别型  |                  0或1                  |
|      fc       |       前置摄像头像素数       |  数值型  |                任意整数                |
|    four_g     |        是否支持4G网络        |  类别型  |                  0或1                  |
|  int_memory   |           内存大小           |  数值型  |                任意整数                |
|     m_dep     |           手机厚度           |  数值型  |                任意实数                |
|   mobile_wt   |           手机重量           |  数值型  |                任意整数                |
|    n_cores    |         处理器核心数         |  数值型  |                任意整数                |
|      pc       |       后置摄像头像素数       |  数值型  |                任意整数                |
|   px_height   |        屏幕高度像素数        |  数值型  |                任意整数                |
|   px_width    |        屏幕宽度像素数        |  数值型  |                任意整数                |
|      ram      |        随机存储器大小        |  数值型  |                任意整数                |
|     sc_h      |        屏幕高度英寸数        |  数值型  |                任意整数                |
|     sc_w      |        屏幕宽度英寸数        |  数值型  |                任意整数                |
|   talk_time   | 单次充电最长通话时间（小时） |  数值型  |                任意整数                |
|    three_g    |        是否支持3G网络        |  类别型  |                  0或1                  |
| touch_screen  |        是否有触屏功能        |  类别型  |                  0或1                  |
|     wifi      |        是否有wifi功能        |  类别型  |                  0或1                  |
|  price_range  |   手机价格区间（目标变量）   |  类别型  | 0（低）、1（中低）、2（中高）、3（高） |

## 实验方法

使用Python语言和sklearn库，分别构建决策树模型和其他模型（如逻辑回归、支持向量机、随机森林等），并比较它们的性能指标（如准确率、精确率、召回率、F1分数等）。

## 实验结果

决策树模型在测试集上的准确率为0.7675，其他模型的准确率最高达到`MLPClassifier: 0.9675`。决策树模型在各个类别上的精确率、召回率和F1分数也较高，说明决策树模型对手机价格分类具有较好的预测能力。决策树模型的优点是简单易懂，计算速度快，可以处理多种类型的数据。决策树模型的缺点是容易过拟合，对噪声敏感，特征之间存在相互关联时表现较差。

**决策树模型**

![](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202306061012468.png)

**其他模型总和**

![](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202306061012503.png)

## 具体实验过程

### 实验分析

决策树模型是一种基于树形结构进行决策判断的模型，它通过多个条件判别过程将数据集分类，最终获取需要的结果。决策树模型的构建和评估都与信息熵密切相关。信息熵是用来度量样本纯度的指标，信息熵越小，样本纯度越高。决策树模型需要“最大化信息增益”来对节点进行划分，信息增益是指特征对训练数据集的信息熵和条件信息熵之差。一般选择信息增益最大的特征作为划分依据。决策树模型可以通过可视化的方式查看每个节点的判断条件和分类结果，方便理解和解释。

### 数据处理

首先，导入所需的库和数据集，并查看数据集的基本信息。代码如下：

```python
# 导入所需的库
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 读取数据集
data = pd.read_csv('https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification')

# 查看数据集基本信息
data.info()
```

输出结果如下：

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2000 entries, 0 to 1999
Data columns (total 21 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   battery_power   2000 non-null   int64  
 1   blue            2000 non-null   int64  
 2   clock_speed     2000 non-null   float64
 3   dual_sim        2000 non-null   int64  
 4   fc              2000 non-null   int64  
 5   four_g          2000 non-null   int64  
 6   int_memory      2000 non-null   int64  
 7   m_dep           2000 non-null   float64
 8   mobile_wt       2000 non-null   int64  
 9   n_cores         2000 non-null   int64  
 10  pc              2000 non-null   int64  
 11  px_height       2000 non-null   int64  
 12  px_width        2000 non-null   int64  
 13  ram             2000 non-null   int64  
 14  sc_h            2000 non-null   int64  
 15  sc_w            2000 non-null   int64  
 16  talk_time       2000 non-null   int64  
 17  three_g         2000 non-null   int64  
 18  touch_screen    2000 non-null   int64  
 19  wifi            2000 non-null   int64  
 20  price_range     2000 non-null   int64  
dtypes: float64(2), int64(19)
memory usage: 328.2 KB
```

发现数据集没有缺失值,没有重复值。然后，使用sklearn库中的train_test_split函数将数据集划分为训练集和测试集，比例为8:2，并设置随机种子为0。代码如下：

```python
# 对类别特征进行编码
le = LabelEncoder()
data['blue'] = le.fit
```

**要注意数据是需要做标准化处理的**

为了避免量纲比较大的特征将量纲比较小的

![](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202306052043353.png)

### 决策树过拟合化的问题探讨

决策树模型的过拟合问题是指模型过度地拟合了训练数据，而没有考虑到泛化能力，导致对新数据的测试集预测结果差。过拟合的原因可能有以下几个方面：

- 特征维度过多，模型假设过于复杂，参数过多，导致模型有过高的自由度，容易捕捉到数据中的噪声或异常值。
- 训练数据过少，或者分布不均匀，导致模型无法学习到数据的真实规律，而只是记住了训练数据的特点。
- 决策树的深度过深，或者叶子节点的样本数过少，导致决策树的模型过于复杂，容易造成对训练数据的过度拟合。

判断决策树模型是否过拟合，可以通过以下几种方法：

- 观察决策树模型在训练集和测试集上的性能指标（如准确率、精确率、召回率、F1分数等），如果训练集上的性能指标远高于测试集上的性能指标，说明模型可能存在过拟合。
- 观察决策树模型的结构，如果决策树的深度特别深特别深以至于叶子节点中的对象只剩下一个或者很少，说明模型可能存在过拟合。
- 使用交叉验证的方法，将数据集分为k个子集，每次使用k-1个子集作为训练集，剩下一个子集作为测试集，重复k次，计算每次的性能指标，并求平均值。如果平均值较低，说明模型可能存在过拟合。

解决决策树模型的过拟合问题，可以通过以下几种方法：

- 减少特征维度，选择与目标变量相关性较高的特征，或者使用降维技术（如主成分分析、线性判别分析等）进行特征提取。
- 增加训练数据量，或者使用数据增强技术（如旋转、缩放、裁剪等）生成更多的训练数据。
- 对决策树进行剪枝操作，即删除一些不重要或者不必要的节点或分支。剪枝有预剪枝和后剪枝两种方式。预剪枝是在生成决策树之前就设置一些条件（如最大深度、最小样本数等），防止决策树生长过长。后剪枝是在生成决策树之后再对其进行简化，比如删除一些对分类结果影响不大的节点或分支。

决策树剪枝是一种减少过拟合的方法，它可以通过删除一些不重要或不必要的节点或分支来简化决策树的结构，提高模型的泛化能力。决策树剪枝有两种主要的方式：预剪枝和后剪枝。

预剪枝是在生成决策树的过程中，对每个待划分的特征，根据验证集的精确度来决定是否进行划分。如果划分后的精确度高于或等于划分前的精确度，则进行划分；否则，将该特征设为叶子节点，标签为训练集中样本数最多的类别。预剪枝可以避免生成过于复杂的决策树，但可能会导致欠拟合。

后剪枝是在生成完整的决策树之后，自下而上地对每个内部节点进行评估，根据损失函数或验证集的精确度来决定是否将其替换为叶子节点。如果替换后的损失函数减小或精确度提高，则进行替换；否则，保留原节点。后剪枝可以保留更多的信息，但计算开销较大。

下面给出一些关于决策树剪枝的代码示例。

- 预剪枝代码示例：

```python
# 导入所需的库
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score

# 加载数据集
X, y = load_iris(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

# 实例化决策树，并设置预剪枝参数
# 这里设置了最大深度为3，最小样本数为4
clf = DecisionTreeClassifier(max_depth=3, min_samples_leaf=4, random_state=0)

# 拟合训练数据
clf.fit(X_train, y_train)

# 预测测试数据
y_pred = clf.predict(X_test)

# 计算准确率
print(accuracy_score(y_test, y_pred)) # 输出 0.9736842105263158
```

- 后剪枝代码示例：

```python
# 导入所需的库
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import accuracy_score

# 加载数据集
X, y = load_breast_cancer(return_X_y=True)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

# 实例化决策树，并设置后剪枝参数
# 这里设置了ccp_alpha为0.006，表示损失函数中树复杂度的权重
clf = DecisionTreeClassifier(ccp_alpha=0.006, random_state=0)

# 拟合训练数据
clf.fit(X_train, y_train)

# 预测测试数据
y_pred = clf.predict(X_test)

# 计算准确率
print(accuracy_score(y_test, y_pred)) # 输出 0.916083916083916

```

### PCA降维

考虑是否需要PCA降维，经验之谈特征数小于50基本上不太需要降维处理。

PCA降维是一种常用的数据分析方法，它可以通过提取数据的主要特征分量来减少数据的维度，从而降低数据的复杂度和噪声，提高数据的可视化和处理效率。

判断是否需要进行PCA降维，一般有以下几个方面的考虑：

- 数据的维度是否过高，导致计算量大，效率低，或者出现维度灾难的问题。
- 数据的特征是否存在多重共线性，即特征之间是否有较强的相关性，导致冗余信息多，模型不稳定。
- 数据的特征是否能够反映数据的本质信息，即特征是否具有较高的方差，能够区分不同的数据类别或者规律。

如果以上问题中有一个或多个成立，那么就可以考虑使用PCA降维。

具体地，可以通过以下几个步骤来判断是否需要进行PCA降维：

- 对数据进行标准化处理，使得每个特征的均值为0，方差为1。
- 计算数据的协方差矩阵，得到每个特征之间的协方差值。如果协方差值接近于0，则说明两个特征之间没有相关性；如果协方差值为正，则说明两个特征之间有正相关性；如果协方差值为负，则说明两个特征之间有负相关性。
- 对协方差矩阵进行特征值分解或者奇异值分解，得到每个特征对应的特征值和特征向量。特征值表示了每个特征向量所包含的信息量，也就是方差大小。
- 选择合适的主成分个数k，即降维后的维度。一般有以下几种方法：
    - 根据经验或者领域知识，直接指定k的值。
    - 根据累计贡献率来确定k的值。累计贡献率是指前k个主成分的方差和占总方差的比例。一般选择累计贡献率达到85%~95%时对应的k值。
    - 根据平均贡献率来确定k的值。平均贡献率是指每个主成分的方差占总方差的比例。一般选择平均贡献率大于平均水平时对应的k值。
    - 根据碎石图（scree plot）来确定k的值。碎石图是指将每个主成分的方差按降序排列后绘制成折线图。一般选择折线图出现拐点时对应的k值。
- 根据选择的k值，取前k个最大的特征值对应的特征向量组成一个投影矩阵，将原始数据乘以投影矩阵得到降维后的数据。

但是因为这里的数据集不大，我们完全可以用试验法实验。

```python
import numpy as np
from sklearn.decomposition import PCA

for i in range(2,20):
    pca = PCA(n_components=19)
    new_train = pca.fit_transform(x_train)
    new_test = pca.fit_transform(x_test)

    # print(pca.explained_variance_ratio_)

    # print(pca.singular_values_)

    # 标准化数据 
    ss=StandardScaler()
    ss.fit(new_train)
    new_train = ss.transform(new_train)
    ss.fit(new_test)
    new_test = ss.transform(new_test)

    dtree2 = DecisionTreeClassifier(criterion="gini")
    dtree2.fit(new_train,y_train)

    y_t2 = dtree2.predict(new_test)
    # print(y_t2)

    # 正确率
    print("维度:  ",i ,"\t正确率：   ",np.sum((y_test == y_t2)) / y_test.size)
```

![](https://124newblog-1309411887.cos.ap-nanjing.myqcloud.com/images/202306052033480.png)

很明显准确率大大下降，所以是不需要PCA降维的。

### 超参数选择

在后面的SVC、Logistic、LinearSVC、MLP模型中需要进行超参数选择。这这里选取了两种搜索。

SVC、Logistic、LinearSVC、MLP模型都是一些常用的机器学习算法，它们都有一些超参数，也就是在训练模型之前需要设定的参数，这些参数会影响模型的性能和泛化能力。超参数选择是指根据数据集和目标函数，寻找最优的超参数组合，使得模型在测试集上达到最佳的效果。

GridSearchCV和RandomizedSearchCV是两种常用的超参数选择方法，它们都属于sklearn.model_selection模块，可以对模型进行交叉验证和网格搜索。它们的区别在于：

- GridSearchCV是对所有可能的超参数组合进行穷举搜索，找到最优的参数值。
- RandomizedSearchCV是对超参数空间进行随机采样，根据给定的迭代次数或时间限制，找到最优的参数值。

GridSearchCV和RandomizedSearchCV都可以用来选择SVC、Logistic、LinearSVC、MLP模型中的超参数，具体的步骤如下：

- 首先，定义一个超参数字典，包含要搜索的参数名称和取值范围。例如，对于SVC模型，可以定义如下字典：

```python
param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
    'gamma': ['scale', 'auto']
}
```

- 然后，创建一个GridSearchCV或RandomizedSearchCV对象，传入模型、超参数字典、交叉验证折数等参数。例如，对于SVC模型，可以创建如下对象：

```python
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV

svc = SVC()
grid_search = GridSearchCV(svc, param_grid, cv=5)
random_search = RandomizedSearchCV(svc, param_grid, cv=5, n_iter=10)
```

- 接着，使用fit方法在训练集上进行超参数搜索。例如：

```python
grid_search.fit(X_train, y_train)
random_search.fit(X_train, y_train)
```

- 最后，使用best_params_属性查看最优的超参数组合，使用best_score_属性查看最优的交叉验证分数。例如：

```python
print(grid_search.best_params_)
print(grid_search.best_score_)
print(random_search.best_params_)
print(random_search.best_score_)
```

- 对于其他模型，如Logistic、LinearSVC、MLP等，可以参考sklearn官方文档 中的相关示例和说明。

## 源码

### **决策树模型**

```python
# 数据处理
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
# 绘图
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sn # mpl的拓展
from sklearn.tree import plot_tree
# 决策树
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

mdata=pd.read_csv("/Users/cc/Library/CloudStorage/OneDrive-个人/大三上课程存档/python/结课答辩/train.csv")

# 先查看数据(data exploratory)
# Displaying the data types
mdata.dtypes

# Displaying the table data
mdata.head()

# Displaying dimensions
# appear 2000 rows 21 col, feature = 21
mdata.shape

# data cleaning(当前实验是预测price_range所以训练的Input要除去这个特征)
desdata = mdata.iloc[ : , : -1]
# 查看训练数据
desdata.describe()

mdata.isna().sum()

plt.figure(figsize=(12,8))
# 查看数据之间的依赖关系，特征之间的相关性取值为[-1,1]，取值接近-1，表示反相关，类似反比例函数，取值接近1，表正相关
dfcorr = mdata.corr()
sn.heatmap(dfcorr)

g = sn.FacetGrid(mdata,col="price_range", hue="price_range",height=6)
g.map(sn.histplot, 'ram');
g.add_legend();

plt.figure(figsize=(14,8))
sn.barplot(data=mdata, x=mdata['four_g'],y=mdata['three_g'],hue="price_range")

plt.figure(figsize=(13,8))
sn.scatterplot(data=mdata,x=mdata['fc'],y=mdata['pc'],hue="price_range")
plt.show()

# 点太多了挤在一张图不好观察
# plt.figure(figsize=(13,8))
# sn.scatterplot(data=mdata,x=mdata['px_width'],y=mdata['px_height'],hue="price_range")
# plt.show()

g = sn.FacetGrid(mdata,col="price_range", hue="price_range",height=6)
g.map(plt.scatter, x=mdata['px_width'],y=mdata['px_height']);
g.add_legend();

g = sn.FacetGrid(mdata,col="price_range", hue="price_range",height=6)
g.map(plt.scatter, x=mdata['sc_w'],y=mdata['sc_h']);
g.add_legend();

# 训练集数据
X = mdata.iloc[:, 1 : -1].values #  除去最后一列price_range
Y = mdata.iloc[:, -1] # price_range

# 标准化数据 
ss = StandardScaler()
ss.fit(X)
X = ss.transform(X)

x_train, x_test, y_train, y_test=train_test_split(X,Y,test_size=0.2, shuffle=True, random_state=20)

dtree = DecisionTreeClassifier(criterion="gini")
dtree.fit(x_train,y_train)

y_t = dtree.predict(x_test)
print(y_t)

# 查看正确率
np.sum( (y_test == y_t)) / y_test.size

from sklearn.metrics import mean_absolute_error
from sklearn.tree import DecisionTreeRegressor

def get_mae(max_leaf_nodes, x_train, x_test, y_train, y_test):
    model = DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes, random_state=0,criterion="gini")
    model.fit(x_train, y_train)
    preds_val = model.predict(x_test)
    mae = mean_absolute_error(y_test, preds_val)
    return(mae)

x_max_leaf_nodes_test = []
x_max_leaf_nodes_train = []
y_my_mae_test = []
y_my_mae_train = []

print("测试集")
for max_leaf_nodes in [2,3,4,5,6,7,8,9, 10, 20, 25,50,75,100,150,200]:
    my_mae = get_mae(max_leaf_nodes,  x_train, x_test, y_train, y_test)
    x_max_leaf_nodes_test.append(max_leaf_nodes)
    y_my_mae_test.append(my_mae)
    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %f" %(max_leaf_nodes, my_mae))

print("训练集")
for max_leaf_nodes in [2,3,4,5,6,7,8,9, 10, 20, 25,50,75,100,150,200]:
    my_mae = get_mae(max_leaf_nodes,  x_train, x_train, y_train, y_train)
    x_max_leaf_nodes_train.append(max_leaf_nodes)
    y_my_mae_train.append(my_mae)
    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %f" %(max_leaf_nodes, my_mae))
5
sn.lineplot(x=x_max_leaf_nodes_test,y=y_my_mae_test)
sn.lineplot(x=x_max_leaf_nodes_train,y=y_my_mae_train )

dtree = DecisionTreeClassifier(criterion="gini",max_leaf_nodes=15)
dtree.fit(x_train,y_train)
y_t = dtree.predict(x_test)
np.sum( (y_test == y_t)) / y_test.size

plt.figure(figsize=(15,15))
plot_tree(dtree, max_depth = 1,  # Draw upto depth of 3
            rounded = True, # Rounded boxes
            filled = True,  # Boxes filled with color
            impurity = True,# Show impurity level
            node_ids = True,# Display node_id
          )
plt.show()

import numpy as np
from sklearn.decomposition import PCA

for i in range(2,20):
    pca = PCA(n_components=19)
    new_train = pca.fit_transform(x_train)
    new_test = pca.fit_transform(x_test)

    # print(pca.explained_variance_ratio_)

    # print(pca.singular_values_)

    # 标准化数据 
    ss=StandardScaler()
    ss.fit(new_train)
    new_train = ss.transform(new_train)
    ss.fit(new_test)
    new_test = ss.transform(new_test)

    dtree2 = DecisionTreeClassifier(criterion="gini")
    dtree2.fit(new_train,y_train)

    y_t2 = dtree2.predict(new_test)
    # print(y_t2)

    # 正确率
    print("维度:  ",i ,"\t正确率：   ",np.sum((y_test == y_t2)) / y_test.size)
```

### SVC、Logistic、LinearSVC、MLP模型

```python
# %%
pip install pandas_profiling

# %%
import warnings
warnings.filterwarnings("ignore")

# %% [markdown]
# ## 导入包

# %%
%matplotlib inline
import numpy as np
import pandas as pd
import pandas_profiling
import matplotlib.pyplot as plt
import seaborn as sns

# %% [markdown]
# ## 导入数据

# %%
data = pd.read_csv('D:/Learning/2022秋/python/Mobile Price Classification/train.csv')
test = pd.read_csv('D:/Learning/2022秋/python/Mobile Price Classification/test.csv')

# %% [markdown]
# ## 数据分析

# %%
report = pandas_profiling.ProfileReport(data)
report

# %% [markdown]
# 根据上图Correlation，Price_range与RAM的相关性很高

# %%
data.describe()

# %%
data.isna().sum()

# %% [markdown]
# 没有空值

# %%
sns.pairplot(data,hue='price_range')
plt.show()

# %%
df_corr = data.corr()
plt.figure(figsize=(20,16), dpi = 100)
sns.heatmap(data = df_corr, annot = True, fmt = '.2f')
plt.show()

# %%
df_corr.price_range.sort_values()[:-1].plot(kind='barh', figsize = (12,8))

# %% [markdown]
# ### 尝试PCA

# %%
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
pca = PCA(n_components=10)
new_train = pca.fit_transform(X_train)
new_test = pca.fit_transform(X_test)

# 标准化数据 
ss=StandardScaler()
ss.fit(new_train)
new_train = ss.transform(new_train)
new_test = ss.transform(new_test)
dtree2 = DecisionTreeClassifier(criterion="gini")
dtree2.fit(new_train,y_train)
y_t2 = dtree2.predict(new_test)
# 正确率
np.sum( (y_test == y_t2)) / y_test.size

# %% [markdown]
# PCA效果不好，使用所有特征进行建模

# %% [markdown]
# ## 建立模型

# %%
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, StratifiedKFold
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression, SGDClassifier 
from sklearn.svm import LinearSVC ,SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay 
from sklearn.model_selection import GridSearchCV ,RandomizedSearchCV
from sklearn.pipeline import Pipeline 
from sklearn.compose import ColumnTransformer 
from xgboost import XGBClassifier
import operator
np.random.seed(101)

# %%
X=  data.drop(columns='price_range')
y = data.price_range

# %%
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)
## define the models
models = {
    'LogisticRegression': LogisticRegression(),
    'SGDClassifier': SGDClassifier(),    #随机梯度下降分类
    'LinearSVC': LinearSVC(),            #支持向量机 线性分类
    'SVC:': SVC(),
    'KNeighborsClassifier': KNeighborsClassifier(),    #K近邻分类
    'RandomForestClassifier': RandomForestClassifier(),#随机森林
    'AdaBoostClassifier':AdaBoostClassifier(),         #AdaBoost集成分类器
    'MLPClassifier': MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1),  #MLP多层感知机分类
}

# %%
## define the Pipeline

score ={}
def mod(models):
    for name,model in models.items():
        pipeline = Pipeline( steps=[("scaler", MinMaxScaler()),('model', model)])     #离差标准化
        pipeline.fit(X_train, y_train)
        score[name] = pipeline.score(X_test, y_test)
    best = max(score.items(), key=operator.itemgetter(1))[0]    #operator.itemgetter获取某一对象 特定维度的数据
    print(f'Best Estimator : {best} with score = {100*score[best]:.2f}')
          
    return score

results = mod(models)
results

# %% [markdown]
# ## 模型选择

# %%
Skfold = StratifiedKFold(n_splits = 10)    #13折交叉验证
metrics = ['accuracy']                     #性能指标

# %% [markdown]
# ### LinearSVC

# %% [markdown]
# #### GridSearchCV

# %%
svc = LinearSVC()
params = {
    # Parameters that we are going to tune.
    'model__C':[0.005,0.01],
    'model__penalty':['l1','l2']
}
pipeline = Pipeline(steps=[("scaler", MinMaxScaler()),('model', svc)])
grid_svc = GridSearchCV(pipeline, param_grid=params, cv = Skfold)

grid_svc.fit(X_train, y_train)

# %%
grid_svc.best_params_

# %%
predictions_svc = grid_svc.predict(X_test)
confusion_matrix(y_test, predictions_svc)

# %%
print(classification_report(y_test, predictions_svc))

# %%
ConfusionMatrixDisplay.from_estimator(estimator = grid_svc, X = X_test, y = y_test);

# %% [markdown]
# #### RandomizedSearchCV

# %%
# run randomized search
n_iter_search = 15
random_search = RandomizedSearchCV(
    pipeline, param_distributions=params, n_iter=n_iter_search
)
grid_svc.fit(X_train, y_train)

# %%
grid_svc.best_params_

# %%
predictions_svc = grid_svc.predict(X_test)
confusion_matrix(y_test, predictions_svc)

# %% [markdown]
# ### SVC

# %% [markdown]
# #### GridSearchCV

# %%
svc = SVC(probability=True)
param_grid = [
  {'model__C': [1, 10, 100, 1000], 'model__kernel': ['linear']},   #C:正则化参数：
  {'model__C': [1, 10, 100, 1000], 'model__gamma': [0.001, 0.0001], 'model__kernel': ['rbf']},
 ]
pipeline_gsvc = Pipeline(steps=[("scaler", MinMaxScaler()),('model', svc)])
grid_svc = GridSearchCV(pipeline_gsvc, param_grid=param_grid, cv = Skfold)

grid_svc.fit(X_train, y_train)

# %%
grid_svc.best_params_

# %% [markdown]
# #### RandomizedSearchCV

# %%
svc = SVC(probability=True)
params2 = [
  {'model__C': [1, 10, 100, 1000], 'model__kernel': ['linear']},   #C:正则化参数：
  {'model__C': [1, 10, 100, 1000], 'model__gamma': [0.001, 0.0001], 'model__kernel': ['rbf']},
 ]
pipeline_rsvc = Pipeline(steps=[("scaler", MinMaxScaler()),('model', svc)])
#n_iter_search = 15
random_search = RandomizedSearchCV(
    pipeline_rsvc, param_distributions=params2, n_iter=15
)
random_search.fit(X_train, y_train)

# %%
random_search.best_params_

# %%
predictions_svc = grid_svc.predict(X_test)
confusion_matrix(y_test, predictions_svc)

# %%
ConfusionMatrixDisplay.from_estimator(estimator = grid_svc, X = X_test, y = y_test);

# %%
print(classification_report(y_test, predictions_svc))

# %%
print('SVC模型预测准确率为：', accuracy_score(y_test, predictions_svc))

# %%
print('SVC模型十折交叉验证准确度为：', cross_val_score(svc, X_train, y_train, cv=Skfold).mean())

# %%
print('ROC_AUC_score=', roc_auc_score(y_test, grid_svc.predict_proba(X_test), multi_class='ovr'))

# %%
from sklearn import svm
clf_svc = svm.SVC()
clf_svc.fit(X_train, y_train)

# %%
print('正确率：%f' % ((clf_svc.predict(X_test) == y_test).sum() / X_test.shape[0]))

# %% [markdown]
# ### Logistic Regression

# %%
from sklearn.linear_model import LogisticRegressionCV
clf = LogisticRegressionCV(cv=5, random_state=0).fit(X_train, y_train)
y_pred = clf.predict(X_test)

#clf.predict_proba(X[:2, :]).shape

clf.score(X_test, y_test)

# %% [markdown]
# #### GridSearchCV

# %%
lr = LogisticRegression(max_iter=10000)
params = {
    # Parameters that we are going to tune.
    'model__C':[0.005,10, 1.0, 0.1, 0.01],
    'model__penalty':['l1', 'l2'],
    'model__solver':['lbfgs', 'liblinear', 'sag', 'saga']
}
pipeline = Pipeline(steps=[("scaler", MinMaxScaler()),('model', lr)])
grid_lr = GridSearchCV(pipeline, param_grid=params, cv = Skfold)

grid_lr.fit(X_train, y_train)

# %%
grid_lr.best_params_

# %% [markdown]
# #### RandomizedSearchCV

# %%
lr = LogisticRegression()
paramslr = {
    # Parameters that we are going to tune.
    'model__C':[0.005,10, 1.0, 0.1, 0.01],
    'model__penalty':['l1', 'l2'],
    'model__solver':['lbfgs', 'liblinear', 'sag', 'saga']
}
pipeline_rlr = Pipeline(steps=[("scaler", MinMaxScaler()),('model', lr)])
random_search_lr = RandomizedSearchCV(
    pipeline_rlr, param_distributions=paramslr, n_iter=15
)
random_search_lr.fit(X_train, y_train)

# %%
random_search_lr.best_params_

# %%
predictions_lr = grid_lr.predict(X_test)
confusion_matrix(y_test, predictions_lr)

# %%
print(classification_report(y_test,predictions_lr))

# %%
ConfusionMatrixDisplay.from_estimator(estimator = grid_lr, X = X_test, y = y_test);

# %%
print('LogisticsRegression模型预测准确率为：', accuracy_score(y_test, predictions_lr))

# %%
print('LogisticsRegression模型十折交叉验证准确度为：', cross_val_score(random_search_lr, X_train, y_train, cv=Skfold).mean())

# %%
print('ROC_AUC_score=', roc_auc_score(y_test, grid_lr.predict_proba(X_test), multi_class='ovr'))

# %% [markdown]
# ### 验证曲线

# %%
from sklearn.model_selection import validation_curve
param_range_lr = [0.005,10, 1.0, 0.1, 0.01]
train_scores_lr, test_scores_lr = validation_curve(
        LogisticRegression(), X_train, y_train, param_name="C", param_range=param_range_lr,
    cv=5)
train_scores_lr

# %%
train_mean_lr = np.mean(train_scores_lr, axis=1)
train_std_lr = np.std(train_scores_lr, axis=1)
test_mean_lr = np.mean(test_scores_lr, axis=1)
test_std_lr = np.std(test_scores_lr, axis=1)
plt.plot(param_range_lr, train_mean_lr, color='blue', marker='o', markersize=5, label='training accuracy')
plt.fill_between(param_range_lr, train_mean_lr + train_std_lr, train_mean_lr - train_std_lr, alpha=0.15, color='blue')
plt.plot(param_range_lr, test_mean_lr, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')
plt.fill_between(param_range_lr, test_mean_lr + test_std_lr, test_mean_lr - test_std_lr, alpha=0.15, color='green')
plt.grid()
plt.xscale('log')
plt.legend(loc='lower right')
plt.xlabel('Parameter C')
plt.ylabel('Accuracy')
plt.show()

# %%
accuracy_score(y_test, predictions_lr)

# %% [markdown]
# ### MLP

# %% [markdown]
# #### GridSearchCV

# %%
MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)
parameters = {'solver': ['lbfgs'],
#              'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ],
              'alpha': 10.0 ** -np.arange(1, 10),
              'hidden_layer_sizes':np.arange(10, 15),
              'random_state':[0,1,2,3,4,5,6,7,8,9]}
grid_mlp = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)

grid_mlp.fit(X_train, y_train)

# %%
print(grid_mlp.best_params_)

# %%
grid_mlp.score(X_test, y_test)

# %%
predictions_mlp = grid_mlp.predict(X_test)
confusion_matrix(y_test, predictions_mlp)

# %%
ConfusionMatrixDisplay.from_estimator(estimator = grid_mlp, X = X_test, y = y_test);

# %% [markdown]
# #### RandomizedSearchCV

# %%
params_mlp = {'solver': ['lbfgs'],
              'alpha': 10.0 ** -np.arange(1, 10),
              'hidden_layer_sizes':np.arange(10, 15),
              'random_state':[0,1,2,3,4,5,6,7,8,9]
}
random_search_mlp = RandomizedSearchCV(
    MLPClassifier(1000), param_distributions=params_mlp, n_iter=15
)
random_search_mlp.fit(X_train, y_train)

# %%
random_search_mlp.best_params_

# %%
random_search_mlp.score(X_test, y_test)

# %%
ConfusionMatrixDisplay.from_estimator(estimator = random_search_mlp, X = X_test, y = y_test);

# %% [markdown]
# ### Gaussian Naive Bayes

# %% [markdown]
# **特征间的相关性较低，贝叶斯模型的预测结果较好**

# %%
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
y_pred = gnb.fit(X_train, y_train).predict(X_test)
print("Number of mislabeled points out of a total %d points : %d" % (X_test.shape[0], (y_test != y_pred).sum()))

# %% [markdown]
# ### 预测

# %%
test = test.drop(columns='id')
grid_svc.predict(test)



```

